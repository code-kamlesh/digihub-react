{"ast":null,"code":"import { AbstractTokenizer } from './AbstractTokenizer.js';\nimport { EndOfStreamError } from 'peek-readable';\nimport * as fs from './FsPromise.js';\nexport class FileTokenizer extends AbstractTokenizer {\n  constructor(fd, fileInfo) {\n    super(fileInfo);\n    this.fd = fd;\n  }\n  /**\r\n   * Read buffer from file\r\n   * @param uint8Array - Uint8Array to write result to\r\n   * @param options - Read behaviour options\r\n   * @returns Promise number of bytes read\r\n   */\n\n\n  async readBuffer(uint8Array, options) {\n    const normOptions = this.normalizeOptions(uint8Array, options);\n    this.position = normOptions.position;\n    const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\n    this.position += res.bytesRead;\n\n    if (res.bytesRead < normOptions.length && (!options || !options.mayBeLess)) {\n      throw new EndOfStreamError();\n    }\n\n    return res.bytesRead;\n  }\n  /**\r\n   * Peek buffer from file\r\n   * @param uint8Array - Uint8Array (or Buffer) to write data to\r\n   * @param options - Read behaviour options\r\n   * @returns Promise number of bytes read\r\n   */\n\n\n  async peekBuffer(uint8Array, options) {\n    const normOptions = this.normalizeOptions(uint8Array, options);\n    const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\n\n    if (!normOptions.mayBeLess && res.bytesRead < normOptions.length) {\n      throw new EndOfStreamError();\n    }\n\n    return res.bytesRead;\n  }\n\n  async close() {\n    return fs.close(this.fd);\n  }\n\n}\nexport async function fromFile(sourceFilePath) {\n  const stat = await fs.stat(sourceFilePath);\n\n  if (!stat.isFile) {\n    throw new Error(`File not a file: ${sourceFilePath}`);\n  }\n\n  const fd = await fs.open(sourceFilePath, 'r');\n  return new FileTokenizer(fd, {\n    path: sourceFilePath,\n    size: stat.size\n  });\n}","map":{"version":3,"sources":["D:/Tata_Strive/WebApplication/digiHub/trunk/digiHubWeb/node_modules/strtok3/lib/FileTokenizer.js"],"names":["AbstractTokenizer","EndOfStreamError","fs","FileTokenizer","constructor","fd","fileInfo","readBuffer","uint8Array","options","normOptions","normalizeOptions","position","res","read","offset","length","bytesRead","mayBeLess","peekBuffer","close","fromFile","sourceFilePath","stat","isFile","Error","open","path","size"],"mappings":"AAAA,SAASA,iBAAT,QAAkC,wBAAlC;AACA,SAASC,gBAAT,QAAiC,eAAjC;AACA,OAAO,KAAKC,EAAZ,MAAoB,gBAApB;AACA,OAAO,MAAMC,aAAN,SAA4BH,iBAA5B,CAA8C;AACjDI,EAAAA,WAAW,CAACC,EAAD,EAAKC,QAAL,EAAe;AACtB,UAAMA,QAAN;AACA,SAAKD,EAAL,GAAUA,EAAV;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACoB,QAAVE,UAAU,CAACC,UAAD,EAAaC,OAAb,EAAsB;AAClC,UAAMC,WAAW,GAAG,KAAKC,gBAAL,CAAsBH,UAAtB,EAAkCC,OAAlC,CAApB;AACA,SAAKG,QAAL,GAAgBF,WAAW,CAACE,QAA5B;AACA,UAAMC,GAAG,GAAG,MAAMX,EAAE,CAACY,IAAH,CAAQ,KAAKT,EAAb,EAAiBG,UAAjB,EAA6BE,WAAW,CAACK,MAAzC,EAAiDL,WAAW,CAACM,MAA7D,EAAqEN,WAAW,CAACE,QAAjF,CAAlB;AACA,SAAKA,QAAL,IAAiBC,GAAG,CAACI,SAArB;;AACA,QAAIJ,GAAG,CAACI,SAAJ,GAAgBP,WAAW,CAACM,MAA5B,KAAuC,CAACP,OAAD,IAAY,CAACA,OAAO,CAACS,SAA5D,CAAJ,EAA4E;AACxE,YAAM,IAAIjB,gBAAJ,EAAN;AACH;;AACD,WAAOY,GAAG,CAACI,SAAX;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACoB,QAAVE,UAAU,CAACX,UAAD,EAAaC,OAAb,EAAsB;AAClC,UAAMC,WAAW,GAAG,KAAKC,gBAAL,CAAsBH,UAAtB,EAAkCC,OAAlC,CAApB;AACA,UAAMI,GAAG,GAAG,MAAMX,EAAE,CAACY,IAAH,CAAQ,KAAKT,EAAb,EAAiBG,UAAjB,EAA6BE,WAAW,CAACK,MAAzC,EAAiDL,WAAW,CAACM,MAA7D,EAAqEN,WAAW,CAACE,QAAjF,CAAlB;;AACA,QAAK,CAACF,WAAW,CAACQ,SAAd,IAA4BL,GAAG,CAACI,SAAJ,GAAgBP,WAAW,CAACM,MAA5D,EAAoE;AAChE,YAAM,IAAIf,gBAAJ,EAAN;AACH;;AACD,WAAOY,GAAG,CAACI,SAAX;AACH;;AACU,QAALG,KAAK,GAAG;AACV,WAAOlB,EAAE,CAACkB,KAAH,CAAS,KAAKf,EAAd,CAAP;AACH;;AArCgD;AAuCrD,OAAO,eAAegB,QAAf,CAAwBC,cAAxB,EAAwC;AAC3C,QAAMC,IAAI,GAAG,MAAMrB,EAAE,CAACqB,IAAH,CAAQD,cAAR,CAAnB;;AACA,MAAI,CAACC,IAAI,CAACC,MAAV,EAAkB;AACd,UAAM,IAAIC,KAAJ,CAAW,oBAAmBH,cAAe,EAA7C,CAAN;AACH;;AACD,QAAMjB,EAAE,GAAG,MAAMH,EAAE,CAACwB,IAAH,CAAQJ,cAAR,EAAwB,GAAxB,CAAjB;AACA,SAAO,IAAInB,aAAJ,CAAkBE,EAAlB,EAAsB;AAAEsB,IAAAA,IAAI,EAAEL,cAAR;AAAwBM,IAAAA,IAAI,EAAEL,IAAI,CAACK;AAAnC,GAAtB,CAAP;AACH","sourcesContent":["import { AbstractTokenizer } from './AbstractTokenizer.js';\r\nimport { EndOfStreamError } from 'peek-readable';\r\nimport * as fs from './FsPromise.js';\r\nexport class FileTokenizer extends AbstractTokenizer {\r\n    constructor(fd, fileInfo) {\r\n        super(fileInfo);\r\n        this.fd = fd;\r\n    }\r\n    /**\r\n     * Read buffer from file\r\n     * @param uint8Array - Uint8Array to write result to\r\n     * @param options - Read behaviour options\r\n     * @returns Promise number of bytes read\r\n     */\r\n    async readBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        this.position = normOptions.position;\r\n        const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\r\n        this.position += res.bytesRead;\r\n        if (res.bytesRead < normOptions.length && (!options || !options.mayBeLess)) {\r\n            throw new EndOfStreamError();\r\n        }\r\n        return res.bytesRead;\r\n    }\r\n    /**\r\n     * Peek buffer from file\r\n     * @param uint8Array - Uint8Array (or Buffer) to write data to\r\n     * @param options - Read behaviour options\r\n     * @returns Promise number of bytes read\r\n     */\r\n    async peekBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        const res = await fs.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\r\n        if ((!normOptions.mayBeLess) && res.bytesRead < normOptions.length) {\r\n            throw new EndOfStreamError();\r\n        }\r\n        return res.bytesRead;\r\n    }\r\n    async close() {\r\n        return fs.close(this.fd);\r\n    }\r\n}\r\nexport async function fromFile(sourceFilePath) {\r\n    const stat = await fs.stat(sourceFilePath);\r\n    if (!stat.isFile) {\r\n        throw new Error(`File not a file: ${sourceFilePath}`);\r\n    }\r\n    const fd = await fs.open(sourceFilePath, 'r');\r\n    return new FileTokenizer(fd, { path: sourceFilePath, size: stat.size });\r\n}\r\n"]},"metadata":{},"sourceType":"module"}