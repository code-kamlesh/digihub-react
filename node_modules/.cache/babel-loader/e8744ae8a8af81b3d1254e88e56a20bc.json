{"ast":null,"code":"import { EndOfStreamError } from 'peek-readable';\nimport { Buffer } from 'node:buffer';\n/**\r\n * Core tokenizer\r\n */\n\nexport class AbstractTokenizer {\n  constructor(fileInfo) {\n    /**\r\n     * Tokenizer-stream position\r\n     */\n    this.position = 0;\n    this.numBuffer = new Uint8Array(8);\n    this.fileInfo = fileInfo ? fileInfo : {};\n  }\n  /**\r\n   * Read a token from the tokenizer-stream\r\n   * @param token - The token to read\r\n   * @param position - If provided, the desired position in the tokenizer-stream\r\n   * @returns Promise with token data\r\n   */\n\n\n  async readToken(token, position = this.position) {\n    const uint8Array = Buffer.alloc(token.len);\n    const len = await this.readBuffer(uint8Array, {\n      position\n    });\n    if (len < token.len) throw new EndOfStreamError();\n    return token.get(uint8Array, 0);\n  }\n  /**\r\n   * Peek a token from the tokenizer-stream.\r\n   * @param token - Token to peek from the tokenizer-stream.\r\n   * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.\r\n   * @returns Promise with token data\r\n   */\n\n\n  async peekToken(token, position = this.position) {\n    const uint8Array = Buffer.alloc(token.len);\n    const len = await this.peekBuffer(uint8Array, {\n      position\n    });\n    if (len < token.len) throw new EndOfStreamError();\n    return token.get(uint8Array, 0);\n  }\n  /**\r\n   * Read a numeric token from the stream\r\n   * @param token - Numeric token\r\n   * @returns Promise with number\r\n   */\n\n\n  async readNumber(token) {\n    const len = await this.readBuffer(this.numBuffer, {\n      length: token.len\n    });\n    if (len < token.len) throw new EndOfStreamError();\n    return token.get(this.numBuffer, 0);\n  }\n  /**\r\n   * Read a numeric token from the stream\r\n   * @param token - Numeric token\r\n   * @returns Promise with number\r\n   */\n\n\n  async peekNumber(token) {\n    const len = await this.peekBuffer(this.numBuffer, {\n      length: token.len\n    });\n    if (len < token.len) throw new EndOfStreamError();\n    return token.get(this.numBuffer, 0);\n  }\n  /**\r\n   *  Ignore number of bytes, advances the pointer in under tokenizer-stream.\r\n   * @param length - Number of bytes to ignore\r\n   * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available\r\n   */\n\n\n  async ignore(length) {\n    if (this.fileInfo.size !== undefined) {\n      const bytesLeft = this.fileInfo.size - this.position;\n\n      if (length > bytesLeft) {\n        this.position += bytesLeft;\n        return bytesLeft;\n      }\n    }\n\n    this.position += length;\n    return length;\n  }\n\n  async close() {// empty\n  }\n\n  normalizeOptions(uint8Array, options) {\n    if (options && options.position !== undefined && options.position < this.position) {\n      throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n    }\n\n    if (options) {\n      return {\n        mayBeLess: options.mayBeLess === true,\n        offset: options.offset ? options.offset : 0,\n        length: options.length ? options.length : uint8Array.length - (options.offset ? options.offset : 0),\n        position: options.position ? options.position : this.position\n      };\n    }\n\n    return {\n      mayBeLess: false,\n      offset: 0,\n      length: uint8Array.length,\n      position: this.position\n    };\n  }\n\n}","map":{"version":3,"sources":["D:/Tata_Strive/WebApplication/digiHub/trunk/digiHubWeb/node_modules/strtok3/lib/AbstractTokenizer.js"],"names":["EndOfStreamError","Buffer","AbstractTokenizer","constructor","fileInfo","position","numBuffer","Uint8Array","readToken","token","uint8Array","alloc","len","readBuffer","get","peekToken","peekBuffer","readNumber","length","peekNumber","ignore","size","undefined","bytesLeft","close","normalizeOptions","options","Error","mayBeLess","offset"],"mappings":"AAAA,SAASA,gBAAT,QAAiC,eAAjC;AACA,SAASC,MAAT,QAAuB,aAAvB;AACA;AACA;AACA;;AACA,OAAO,MAAMC,iBAAN,CAAwB;AAC3BC,EAAAA,WAAW,CAACC,QAAD,EAAW;AAClB;AACR;AACA;AACQ,SAAKC,QAAL,GAAgB,CAAhB;AACA,SAAKC,SAAL,GAAiB,IAAIC,UAAJ,CAAe,CAAf,CAAjB;AACA,SAAKH,QAAL,GAAgBA,QAAQ,GAAGA,QAAH,GAAc,EAAtC;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACmB,QAATI,SAAS,CAACC,KAAD,EAAQJ,QAAQ,GAAG,KAAKA,QAAxB,EAAkC;AAC7C,UAAMK,UAAU,GAAGT,MAAM,CAACU,KAAP,CAAaF,KAAK,CAACG,GAAnB,CAAnB;AACA,UAAMA,GAAG,GAAG,MAAM,KAAKC,UAAL,CAAgBH,UAAhB,EAA4B;AAAEL,MAAAA;AAAF,KAA5B,CAAlB;AACA,QAAIO,GAAG,GAAGH,KAAK,CAACG,GAAhB,EACI,MAAM,IAAIZ,gBAAJ,EAAN;AACJ,WAAOS,KAAK,CAACK,GAAN,CAAUJ,UAAV,EAAsB,CAAtB,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;;;AACmB,QAATK,SAAS,CAACN,KAAD,EAAQJ,QAAQ,GAAG,KAAKA,QAAxB,EAAkC;AAC7C,UAAMK,UAAU,GAAGT,MAAM,CAACU,KAAP,CAAaF,KAAK,CAACG,GAAnB,CAAnB;AACA,UAAMA,GAAG,GAAG,MAAM,KAAKI,UAAL,CAAgBN,UAAhB,EAA4B;AAAEL,MAAAA;AAAF,KAA5B,CAAlB;AACA,QAAIO,GAAG,GAAGH,KAAK,CAACG,GAAhB,EACI,MAAM,IAAIZ,gBAAJ,EAAN;AACJ,WAAOS,KAAK,CAACK,GAAN,CAAUJ,UAAV,EAAsB,CAAtB,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;;;AACoB,QAAVO,UAAU,CAACR,KAAD,EAAQ;AACpB,UAAMG,GAAG,GAAG,MAAM,KAAKC,UAAL,CAAgB,KAAKP,SAArB,EAAgC;AAAEY,MAAAA,MAAM,EAAET,KAAK,CAACG;AAAhB,KAAhC,CAAlB;AACA,QAAIA,GAAG,GAAGH,KAAK,CAACG,GAAhB,EACI,MAAM,IAAIZ,gBAAJ,EAAN;AACJ,WAAOS,KAAK,CAACK,GAAN,CAAU,KAAKR,SAAf,EAA0B,CAA1B,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;;;AACoB,QAAVa,UAAU,CAACV,KAAD,EAAQ;AACpB,UAAMG,GAAG,GAAG,MAAM,KAAKI,UAAL,CAAgB,KAAKV,SAArB,EAAgC;AAAEY,MAAAA,MAAM,EAAET,KAAK,CAACG;AAAhB,KAAhC,CAAlB;AACA,QAAIA,GAAG,GAAGH,KAAK,CAACG,GAAhB,EACI,MAAM,IAAIZ,gBAAJ,EAAN;AACJ,WAAOS,KAAK,CAACK,GAAN,CAAU,KAAKR,SAAf,EAA0B,CAA1B,CAAP;AACH;AACD;AACJ;AACA;AACA;AACA;;;AACgB,QAANc,MAAM,CAACF,MAAD,EAAS;AACjB,QAAI,KAAKd,QAAL,CAAciB,IAAd,KAAuBC,SAA3B,EAAsC;AAClC,YAAMC,SAAS,GAAG,KAAKnB,QAAL,CAAciB,IAAd,GAAqB,KAAKhB,QAA5C;;AACA,UAAIa,MAAM,GAAGK,SAAb,EAAwB;AACpB,aAAKlB,QAAL,IAAiBkB,SAAjB;AACA,eAAOA,SAAP;AACH;AACJ;;AACD,SAAKlB,QAAL,IAAiBa,MAAjB;AACA,WAAOA,MAAP;AACH;;AACU,QAALM,KAAK,GAAG,CACV;AACH;;AACDC,EAAAA,gBAAgB,CAACf,UAAD,EAAagB,OAAb,EAAsB;AAClC,QAAIA,OAAO,IAAIA,OAAO,CAACrB,QAAR,KAAqBiB,SAAhC,IAA6CI,OAAO,CAACrB,QAAR,GAAmB,KAAKA,QAAzE,EAAmF;AAC/E,YAAM,IAAIsB,KAAJ,CAAU,uEAAV,CAAN;AACH;;AACD,QAAID,OAAJ,EAAa;AACT,aAAO;AACHE,QAAAA,SAAS,EAAEF,OAAO,CAACE,SAAR,KAAsB,IAD9B;AAEHC,QAAAA,MAAM,EAAEH,OAAO,CAACG,MAAR,GAAiBH,OAAO,CAACG,MAAzB,GAAkC,CAFvC;AAGHX,QAAAA,MAAM,EAAEQ,OAAO,CAACR,MAAR,GAAiBQ,OAAO,CAACR,MAAzB,GAAmCR,UAAU,CAACQ,MAAX,IAAqBQ,OAAO,CAACG,MAAR,GAAiBH,OAAO,CAACG,MAAzB,GAAkC,CAAvD,CAHxC;AAIHxB,QAAAA,QAAQ,EAAEqB,OAAO,CAACrB,QAAR,GAAmBqB,OAAO,CAACrB,QAA3B,GAAsC,KAAKA;AAJlD,OAAP;AAMH;;AACD,WAAO;AACHuB,MAAAA,SAAS,EAAE,KADR;AAEHC,MAAAA,MAAM,EAAE,CAFL;AAGHX,MAAAA,MAAM,EAAER,UAAU,CAACQ,MAHhB;AAIHb,MAAAA,QAAQ,EAAE,KAAKA;AAJZ,KAAP;AAMH;;AA9F0B","sourcesContent":["import { EndOfStreamError } from 'peek-readable';\r\nimport { Buffer } from 'node:buffer';\r\n/**\r\n * Core tokenizer\r\n */\r\nexport class AbstractTokenizer {\r\n    constructor(fileInfo) {\r\n        /**\r\n         * Tokenizer-stream position\r\n         */\r\n        this.position = 0;\r\n        this.numBuffer = new Uint8Array(8);\r\n        this.fileInfo = fileInfo ? fileInfo : {};\r\n    }\r\n    /**\r\n     * Read a token from the tokenizer-stream\r\n     * @param token - The token to read\r\n     * @param position - If provided, the desired position in the tokenizer-stream\r\n     * @returns Promise with token data\r\n     */\r\n    async readToken(token, position = this.position) {\r\n        const uint8Array = Buffer.alloc(token.len);\r\n        const len = await this.readBuffer(uint8Array, { position });\r\n        if (len < token.len)\r\n            throw new EndOfStreamError();\r\n        return token.get(uint8Array, 0);\r\n    }\r\n    /**\r\n     * Peek a token from the tokenizer-stream.\r\n     * @param token - Token to peek from the tokenizer-stream.\r\n     * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.\r\n     * @returns Promise with token data\r\n     */\r\n    async peekToken(token, position = this.position) {\r\n        const uint8Array = Buffer.alloc(token.len);\r\n        const len = await this.peekBuffer(uint8Array, { position });\r\n        if (len < token.len)\r\n            throw new EndOfStreamError();\r\n        return token.get(uint8Array, 0);\r\n    }\r\n    /**\r\n     * Read a numeric token from the stream\r\n     * @param token - Numeric token\r\n     * @returns Promise with number\r\n     */\r\n    async readNumber(token) {\r\n        const len = await this.readBuffer(this.numBuffer, { length: token.len });\r\n        if (len < token.len)\r\n            throw new EndOfStreamError();\r\n        return token.get(this.numBuffer, 0);\r\n    }\r\n    /**\r\n     * Read a numeric token from the stream\r\n     * @param token - Numeric token\r\n     * @returns Promise with number\r\n     */\r\n    async peekNumber(token) {\r\n        const len = await this.peekBuffer(this.numBuffer, { length: token.len });\r\n        if (len < token.len)\r\n            throw new EndOfStreamError();\r\n        return token.get(this.numBuffer, 0);\r\n    }\r\n    /**\r\n     *  Ignore number of bytes, advances the pointer in under tokenizer-stream.\r\n     * @param length - Number of bytes to ignore\r\n     * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available\r\n     */\r\n    async ignore(length) {\r\n        if (this.fileInfo.size !== undefined) {\r\n            const bytesLeft = this.fileInfo.size - this.position;\r\n            if (length > bytesLeft) {\r\n                this.position += bytesLeft;\r\n                return bytesLeft;\r\n            }\r\n        }\r\n        this.position += length;\r\n        return length;\r\n    }\r\n    async close() {\r\n        // empty\r\n    }\r\n    normalizeOptions(uint8Array, options) {\r\n        if (options && options.position !== undefined && options.position < this.position) {\r\n            throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\r\n        }\r\n        if (options) {\r\n            return {\r\n                mayBeLess: options.mayBeLess === true,\r\n                offset: options.offset ? options.offset : 0,\r\n                length: options.length ? options.length : (uint8Array.length - (options.offset ? options.offset : 0)),\r\n                position: options.position ? options.position : this.position\r\n            };\r\n        }\r\n        return {\r\n            mayBeLess: false,\r\n            offset: 0,\r\n            length: uint8Array.length,\r\n            position: this.position\r\n        };\r\n    }\r\n}\r\n"]},"metadata":{},"sourceType":"module"}